{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb4orrLSCF3Buah6E08E0L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhirshahu51/RAG/blob/main/Query_with_Jamba_llamaindex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PmOj7IQp25uX"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index llama-index-llms-ai21 llama-index-llms-huggingface llama-index-llms-huggingface-api llama-index-embeddings-huggingface sentence-transformers llama-index-embeddings-instructor --quiet\n",
        "#llama-index-llms-text-generation-inference\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to make async work well with jupyter notebook\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "JSYmv-Vk4EsV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Envirnment Secret keys\n",
        "from google.colab import userdata\n",
        "key = userdata.get('JAMBA_API') #https://studio.ai21.com/v2/account/api-key"
      ],
      "metadata": {
        "id": "t3V8-hrm4Pk3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from typing import List, Optional\n",
        "from llama_index.core import Settings\n",
        "from IPython.display import Markdown, display\n"
      ],
      "metadata": {
        "id": "xKV46Iwz4Tuo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_index.llms.ai21 import AI21\n",
        "\n",
        "# EITHER\n",
        "\n",
        "os.environ[\"AI21_API_KEY\"] = key\n",
        "llm = AI21()\n",
        "\n",
        "# OR\n",
        "#llm = AI21(api_key=api_key)"
      ],
      "metadata": {
        "id": "KI27GJ6h4p-G"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion_response = llm.complete(\"what is jamba?\")\n",
        "display(Markdown(f'{completion_response}'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "qo-vPV_t5-QV",
        "outputId": "d396d5b0-69ff-4aa8-d1ea-e34b4e532c7e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Jamba is a tool designed to enhance the capabilities of the popular open-source AI model, LLaMA, developed by Meta. It is essentially a \"prompt injection attack\" tool that allows users to manipulate and improve the responses generated by LLaMA. Jamba achieves this by injecting additional context into the prompts, which helps the model produce more accurate, relevant, and creative outputs.\n\nKey features of Jamba include:\n\n1. **Context Injection**: Jamba can insert context into prompts to guide the model's responses more effectively.\n2. **Prompt Engineering**: It assists in crafting better prompts, making the AI's outputs more aligned with user intentions.\n3. **Versatility**: Jamba is compatible with various AI models, not just LLaMA, making it a versatile tool for AI enthusiasts and developers.\n4. **Customization**: Users can customize the injection process to suit their specific needs, enhancing the flexibility of the tool.\n\nJamba has gained popularity among AI developers and researchers for its ability to significantly improve the performance of AI models by fine-tuning how prompts are structured and delivered."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "owzVSiUZ6jsL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}